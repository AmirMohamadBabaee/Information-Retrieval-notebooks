{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5vthoJMuBpn",
    "tags": []
   },
   "source": [
    "# Similarity Modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Information**\n",
    "AmirMohammad Babaei\n",
    "9831011"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_FPiNrFMYmY"
   },
   "source": [
    "Here we are going to implement another similarity other that the BM25 which is the default in Elastic. We want you to implement a tf-idf similarity and test it with same queries in phase2 so that you can get a sense of how well your Elastic tf-idf works. Follow the instructions and fill where ever it says # TODO.  <br>\n",
    "You can contact me in case of any problems via Telegram: @mahvash_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/amir01/.cache/pip/wheels/54/0a/38/7d0b1aabbd644340a94fb8685fd20d9f35814d735973d07f40/parsivar-0.2.3-py3-none-any.whl\n",
      "Processing /home/amir01/.cache/pip/wheels/23/18/48/8fd6ec11da38406b309470566d6f099c04805d2ec61d7829e7/nltk-3.4.5-py3-none-any.whl\n",
      "Requirement already satisfied: six in ./venv/lib/python3.8/site-packages (from nltk==3.4.5->parsivar) (1.16.0)\n",
      "\u001b[31mERROR: hazm 0.7.0 has requirement nltk==3.3, but you'll have nltk 3.4.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: nltk, parsivar\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.3\n",
      "    Uninstalling nltk-3.3:\n",
      "      Successfully uninstalled nltk-3.3\n",
      "Successfully installed nltk-3.4.5 parsivar-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install parsivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "EbwCj28juBps"
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from parsivar import Normalizer, Tokenizer, FindStems\n",
    "from string import punctuation\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BrwsaVsj5ubv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'اعلام زمان قرعه کشی جام باشگاه های فوتسال آسیا'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data in json format\n",
    "file_name = 'IR_data_news_12k.json'\n",
    "def load_docs(file_name):\n",
    "    with open(file_name) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "    \n",
    "data['0']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_remove = True\n",
    "stemming = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(stopwords_path):\n",
    "    stopwords_set = None\n",
    "    with open(stopwords_path, 'r') as f:\n",
    "        stopwords_set = set(f.read().split())\n",
    "    return stopwords_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(words, persian_stopwords_path='./persian-stopwords.txt'):\n",
    "    persian_stopwords = load_stopwords(persian_stopwords_path)\n",
    "    return [word for word in words if word not in persian_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['سلام', 'امروز', 'خواست&خواه', 'تابع', '3', 'امتحان', 'کرد&کن']\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text, stopwords_remove=True, stemming=True):\n",
    "    normalizer = Normalizer()\n",
    "    tokenizer = Tokenizer()\n",
    "    stemmer = FindStems()\n",
    "    \n",
    "    pure_text = re.sub(f'[{punctuation}؟،٪×÷»«]+', '', text)\n",
    "    normal_text = normalizer.normalize(pure_text)\n",
    "    res = tokenizer.tokenize_words(normal_text)\n",
    "    if stemming:\n",
    "        res = list(map(stemmer.convert_to_stem, res))\n",
    "    if stopwords_remove:\n",
    "        res = remove_stopwords(res)\n",
    "    \n",
    "    return res\n",
    "\n",
    "print(preprocess('سلام من امروز می خواهم این تابع را ۳ بار امتحان کنم.', stopwords_remove=stopwords_remove, stemming=stemming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_contents(docs_dict, stopwords_remove=True, stemming=True):\n",
    "    \n",
    "    for docID, body in docs_dict.items():\n",
    "        body['content'] = preprocess(body['content'], stopwords_remove, stemming)\n",
    "        \n",
    "    return docs_dict\n",
    "\n",
    "preprocessed_docs = preprocess_contents(load_docs(file_name), stopwords_remove=stopwords_remove, stemming=stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4xg-Rhk5ub0"
   },
   "outputs": [],
   "source": [
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XDs6hQbv5ub1",
    "outputId": "94331ba2-938f-4f1e-c915-3dd8afa6601a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'content', 'tags', 'date', 'url', 'category'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data keys\n",
    "preprocessed_docs['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs saved in preprocessed_IR_docs.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_index(index, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(index, outp, pickle.HIGHEST_PROTOCOL)\n",
    "        print(f'docs saved in {filename}')\n",
    "        \n",
    "save_index(preprocessed_docs, 'preprocessed_IR_docs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ3Kf58zuBpv"
   },
   "source": [
    "After starting your Elasticsearch on your pc (localhost:9200 is the default) we have to connect to it via the following piece of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example.ini']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('example.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_yyuk50M5ub2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174/26777902.py:2: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(\n"
     ]
    }
   ],
   "source": [
    "# Here we try to connect to Elastic\n",
    "es = Elasticsearch(\n",
    "    cloud_id=config['ELASTIC']['cloud_id'],\n",
    "    http_auth=(config['ELASTIC']['user'], config['ELASTIC']['password'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCY5fnsd5ub5",
    "tags": []
   },
   "source": [
    "## Create tf-idf Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mA8caevuBpx",
    "tags": []
   },
   "source": [
    "### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KGcQKuO6uBpx"
   },
   "outputs": [],
   "source": [
    "# Name of index \n",
    "sm_index_name = 'tfidf_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jAO61WFi5ub6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'tfidf_index'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete index if one does exist\n",
    "if es.indices.exists(index=sm_index_name):\n",
    "    es.indices.delete(index=sm_index_name)\n",
    "\n",
    "# Create index    \n",
    "es.indices.create(index=sm_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMipnzi9uBpy",
    "tags": []
   },
   "source": [
    "### Add documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELD27cX9uBpz"
   },
   "source": [
    "In here we used the bulk doc formatter which was introduced in the first subsection of phase 3. <br>\n",
    "You can find out more in [Here](https://stackoverflow.com/questions/61580963/insert-multiple-documents-in-elasticsearch-bulk-doc-formatter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xhA0gQXe5ub7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "def bulk_sync():\n",
    "    actions = [\n",
    "        {\n",
    "            '_index': sm_index_name,\n",
    "            '_id':doc_id,\n",
    "            '_source': doc\n",
    "        } for doc_id,doc in preprocessed_docs.items()\n",
    "    ]\n",
    "    bulk(es, actions)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2ak5DZ1TuBpz"
   },
   "outputs": [],
   "source": [
    "# run the function to add documents\n",
    "bulk_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KxmyyKf9uBp0",
    "outputId": "633e18c6-3886-4161-c919-99afa7f13e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'count': 12202, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index\n",
    "es.count(index = sm_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csyy2vtEuBp0",
    "tags": []
   },
   "source": [
    "### Configuring a similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2wum2BOuBp0"
   },
   "source": [
    "In order to configure a new similarity function you have to change the similarity from the settings api of the index. This can be done via the function 'put_settings' in python. What we do is to change the 'default' similarity function in Elastic so that it uses the replaced similarity instead. Type of this similarity is set to 'scripted' because tf-idf is not among the pre-defined similarity functions in Elastic anymore. As this similarity is a scripted type the source code of it must be written **by you** and passed to it.<br>\n",
    "> In order for the changes to be applied, first we close the index and change the settings and then reopen it<br>\n",
    "\n",
    "Write the tf-idf code in a string and pass it as a value to the \"source\" key. <br>\n",
    "You can find the variables needed in your code in [Here](https://www.elastic.co/guide/en/elasticsearch/painless/current/painless-similarity-context.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sourse Code of tf-idf similarity\n",
    "```java\n",
    "double tf = Math.log(1 + doc.freq); \n",
    "double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)); \n",
    "double norm = 1/Math.sqrt(doc.length); \n",
    "return query.boost * tf * idf * norm;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "YzQJGr24uBp1"
   },
   "outputs": [],
   "source": [
    "# TODO : uncomment the code bellow, write the tf-idf code in here\n",
    "source_code = \"double tf = Math.log(1 + doc.freq); double idf = Math.log((field.docCount+1.0)/(term.docFreq+1.0)); double norm = 1/Math.sqrt(doc.length); return query.boost * tf * idf * norm;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Wjdp3J3T5ub7",
    "outputId": "b41302cd-777d-4c80-ad4e-ca9865c271e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# closing the index\n",
    "es.indices.close(index=sm_index_name)\n",
    "\n",
    "# applying the settings\n",
    "es.indices.put_settings(index=sm_index_name, \n",
    "                            settings={\n",
    "                                \"similarity\": {\n",
    "                                      \"default\": {\n",
    "                                        \"type\": \"scripted\",\n",
    "                                        \"script\": {\n",
    "                                          # TODO : uncomment the code bellow and pass the suitable parameter\n",
    "                                          \"source\": source_code\n",
    "                                        }\n",
    "                                      }\n",
    "                                }\n",
    "                            }\n",
    "                       )\n",
    "\n",
    "# reopening the index\n",
    "es.indices.open(index=sm_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghBUm8V8uBp1",
    "tags": []
   },
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfMeKtYiN-fu"
   },
   "source": [
    "In this section you have to test your index with same queries you tested phase2. The goal here is to observe how different or simillar your tf-idf Elastic implementation works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654237270680,
     "user": {
      "displayName": "Mahvash Siavashpour",
      "userId": "18425997334276185054"
     },
     "user_tz": -270
    },
    "id": "YWJ5w3unuBp2"
   },
   "outputs": [],
   "source": [
    "# A function that creates appropriate body for our match content type query\n",
    "def get_query(text):\n",
    "    body ={\n",
    "      \"query\": {\n",
    "        \"match\": {\n",
    "          \"content\": f\"{text}\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7UJKTdWuuBp2"
   },
   "outputs": [],
   "source": [
    "queries = [\n",
    "    #TODO : add your queries in string format to this list\n",
    "    get_query(\"ایران\"),\n",
    "    get_query(\"قهرمانی تیم ملی ایران\"),\n",
    "    get_query(\"استمهال\"),\n",
    "    get_query(\"مناقشات سیاسی خاورمیانه\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': {'match': {'content': 'ایران'}}},\n",
       " {'query': {'match': {'content': 'قهرمانی تیم ملی ایران'}}},\n",
       " {'query': {'match': {'content': 'استمهال'}}},\n",
       " {'query': {'match': {'content': 'مناقشات سیاسی خاورمیانه'}}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "d2jhW3twuBp2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174/373466824.py:5: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  res_tfidf = es.search(index=sm_index_name, body=get_query(q), explain=True)\n"
     ]
    }
   ],
   "source": [
    "all_res_tfidf = []\n",
    "\n",
    "\n",
    "for q in queries:\n",
    "    res_tfidf = es.search(index=sm_index_name, body=get_query(q), explain=True)\n",
    "    all_res_tfidf.append(dict(res_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gesmaSYHuBp3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'match': {'content': 'ایران'}}}\n",
      "Score: [0.6754794]: https://www.farsnews.ir/news/14001030000095/آینده-سردار-آزمون-رسما-مشخص-شد\n",
      "Score: [0.27887025]: https://www.farsnews.ir/news/14001107000656/آمار-بازی-ایران-عراق-یوزها-زهردار-از-شیرهای-بین-النهرین\n",
      "Score: [0.26513416]: https://www.farsnews.ir/news/14001217001047/رقابتهای-بین-المللی-تکواندو-جام-فجر|هر-چهار-طلاهای-روز-نخست-به-مردان\n",
      "Score: [0.25457254]: https://www.farsnews.ir/news/14001219000570/مسابقات-قهرمانی-آسیا|-پیروزی-دلچسب-دختران-هندبالیست-جوان-ایران-مقابل\n",
      "Score: [0.25030154]: https://www.farsnews.ir/news/14000921000552/با-حکم-رئیس‌جمهور-مختارپور-رئیس-سازمان-اسناد-و-کتابخانه-ملی-شد\n",
      "Score: [0.24964733]: https://www.farsnews.ir/news/14001219000747/جام-ریاست-فدراسیون-جهانی-تکواندو|-روز-طلایی-بانوان-ایرانی-و-قزاق\n",
      "Score: [0.2478899]: https://www.farsnews.ir/news/14001220000571/نشر-خبر-توقیف-دو-نفتکش-ایرانی-در-این-مقطع-از-مذاکرات-ترفند-آمریکا-برای\n",
      "Score: [0.24641925]: https://www.farsnews.ir/news/14001118000913/کامیابی‌نیا-در-باشگاه-200-تایی‌های-پرسپولیس\n",
      "Score: [0.24298887]: https://www.farsnews.ir/news/14001028001050/سرمربی-استرالیا-ایران-می‌تواند-صدرنشین-شود-از-علاقمندان-به-حافظ-و\n",
      "Score: [0.23803693]: https://www.farsnews.ir/news/14000905000504/نماینده-مجلس-آمریکا-با-ایجاد-آشوب-در-اصفهان-دنبال-برگ-برنده-برای-خود\n",
      "----------------------------\n",
      "{'query': {'match': {'content': 'قهرمانی تیم ملی ایران'}}}\n",
      "Score: [0.850561]: https://www.farsnews.ir/news/14001104000462/زخم‌کاری-هندبال-ایران-به-کویتی‌ها-بلیت-قهرمانی-جهان-رزرو-شد\n",
      "Score: [0.8338711]: https://www.farsnews.ir/news/14001111000656/دست-شاگردان-فرناندز-از-مدال-کوتاه-ماند-هندبال-ایران-چهارم-شد\n",
      "Score: [0.82732844]: https://www.farsnews.ir/news/14001101000440/پس‌لرزه‌های-شکست-عربستان-مقابل-ایران-حمله-سعودی‌ها-به-سرمربی-فرانسوی\n",
      "Score: [0.8089826]: https://www.farsnews.ir/news/14001030000095/آینده-سردار-آزمون-رسما-مشخص-شد\n",
      "Score: [0.80699027]: https://www.farsnews.ir/news/14001216000839/انتخابی-کشتی‌گیر-اعزامی-۸۶-کیلو-به-قهرمانی-آسیا-را-مشخص-می‌کند\n",
      "Score: [0.8044084]: https://www.farsnews.ir/news/14001106000886/سرپوشی-هدف‌مان-کسب-سکوی-آسیا-است--هندبال-ایران-رو-به-پیشرفت-است\n",
      "Score: [0.78955376]: https://www.farsnews.ir/news/14001106000623/شکست-شاگردان-فرناندز-مقابل-نماینده-المپیکی-آسیا-ایران-دوم-صعود-کرد\n",
      "Score: [0.78297466]: https://www.farsnews.ir/news/14001001000619/نایب-قهرمانی-ایران-در-کاتای-آسیا\n",
      "Score: [0.7773602]: https://www.farsnews.ir/news/14001201000616/آغاز-کار-تیم-ملی-زیر-نظر-سرمربی-ارمنستانی-سرگیسیان-وارد-شد\n",
      "Score: [0.7704474]: https://www.farsnews.ir/news/14001118000641/سرمربی-تیم-ملی-والیبال-جوانان-انتخاب-شد\n",
      "----------------------------\n",
      "{'query': {'match': {'content': 'استمهال'}}}\n",
      "Score: [0.7459644]: https://www.farsnews.ir/news/14000819000217/وام-کشاورزان-استمهال-شود\n",
      "Score: [0.6754794]: https://www.farsnews.ir/news/14001030000095/آینده-سردار-آزمون-رسما-مشخص-شد\n",
      "Score: [0.59996486]: https://www.farsnews.ir/news/14001130001158/اعلام-نظر-شورای-نگهبان-درباره-6-طرح-و-لایحه\n",
      "Score: [0.5820514]: https://www.farsnews.ir/news/14001019000650/اختصاصی|-شورای-نگهبان-برای-بررسی-لایحه-رتبه‌بندی-معلمان-از-مجلس-مهلت\n",
      "Score: [0.37030634]: https://www.farsnews.ir/news/14000819000403/درخواست-نماینده-پلدختر-برای-استمهال-بدهی-سیل‌زدگان-به-بانک‌ها\n",
      "Score: [0.32858852]: https://www.farsnews.ir/news/14000813000661/رئیسی-هیچ-بانکی-حق-ندارد-کارخانه‌ای-را-تعطیل-کند\n",
      "Score: [0.2475266]: https://www.farsnews.ir/news/14000921000221/هزینه‌های-مربوط-به-ثبت-اختراعات-و-طرح‌های-صنعتی-مشخص-شد\n",
      "Score: [0.22092496]: https://www.farsnews.ir/news/14001005000744/نسخه-مورد-نقد-مرکز-پژوهش‌ها-قبلاً-از-دستور-کمیسیون-ویژه-طرح-حمایت-از\n",
      "Score: [0.19594769]: https://www.farsnews.ir/news/14000818000187/بانک‌ها-قانون-را-دور-زده-و-ربا-می‌گیرند-رشد-39-درصدی-نقدینگی-و-42\n",
      "Score: [0.1778894]: https://www.farsnews.ir/news/14001108000291/در-نشست-نمایندگان-استان‌های-خوزستان-چهارمحال-و-لرستان-با-رئیسی-چه-گذشت\n",
      "----------------------------\n",
      "{'query': {'match': {'content': 'مناقشات سیاسی خاورمیانه'}}}\n",
      "Score: [0.6754794]: https://www.farsnews.ir/news/14001030000095/آینده-سردار-آزمون-رسما-مشخص-شد\n",
      "Score: [0.5309437]: https://www.farsnews.ir/news/14001012000802/سردار-سلیمانی-شهید-پروژه-نرمالیزاسیون-سیاسی-است\n",
      "Score: [0.49001518]: https://www.farsnews.ir/news/14000730000363/ایران-اجازه-تشکیل-شعبه-2-رژیم-صهیونیستی-را-در-مرزهای-شمال-غرب-خود\n",
      "Score: [0.4494612]: https://www.farsnews.ir/news/14001215000649/آمریکا-اهداف-شوم-خود-را-با-بحران‌سازی‌ها-پیگیری-می‌کند\n",
      "Score: [0.4494612]: https://www.farsnews.ir/news/14001209000540/نگاه-دوگانه-برخی-جریان‌ها-به-یمن-و-اوکراین-نشانه-سرسپردگی‌شان-به\n",
      "Score: [0.43643054]: https://www.farsnews.ir/news/14001130000381/نسخه-انگلیسی-مبارزه-با-فساد\n",
      "Score: [0.3977535]: https://www.farsnews.ir/news/14000817000555/مبارزه-با-استکبار-جهانی-باید-توأمان-سلبی-و-ایجابی-باشد\n",
      "Score: [0.38890928]: https://www.farsnews.ir/news/14001111000120/تداوم-رکوردشکنی-درخواست-خرید-بلیت-جام-جهانی-کدام-کشورها-رکورددار-هستند\n",
      "Score: [0.37405068]: https://www.farsnews.ir/news/14000828000423/نادری- اتاق بازرگانی ایران و برزیل به\n",
      "Score: [0.36154643]: https://www.farsnews.ir/news/14001022000145/رسانه‌ها-و-خبرنگاران-باید-با-حملات-تردید-افکنانه-دشمن-مقابله-کنند\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for res, q in zip(all_res_tfidf, queries):\n",
    "    print(q)\n",
    "    for doc in res['hits']['hits']:\n",
    "        print(f\"Score: [{doc['_score']}]: {doc['_source']['url']}\")\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8pbrwnquBp3"
   },
   "source": [
    "<div dir=\"rtl\">\n",
    "    همانطور که در ادامه مشاهده می شود، داک مربوط به «آینده سردار آزمون رسما مشخص شد» در نتیجه سه کوئری وجود دارد که با توجه به بررسی متن آن متوجه شدم که این داک به اشتباه در این کوئری ها آمده است. این داک دارای کلمه ایران، قهرمانی، مناقشات، سیاسی، خاورمیانه و استمهال نمی باشد و اما دارای تعداد زیادی کلمه تیم می باشد.\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y098-SQQuBp3"
   },
   "source": [
    "![image.png](./images/azmoon-1.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
